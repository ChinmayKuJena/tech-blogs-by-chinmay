<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
body {
  margin: 0;
  padding: 0;
  background-color: #f6f8fa;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
}

.wrapper {
  max-width: 760px;
  margin: 40px auto;
  background: #ffffff;
  padding: 48px;
  border-radius: 12px;
  box-shadow: 0 8px 24px rgba(0,0,0,0.06);
  line-height: 1.7;
  color: #111827;
}

h1 {
  font-size: 34px;
  margin-bottom: 12px;
  line-height: 1.3;
}

.meta {
  font-size: 14px;
  color: #6b7280;
  margin-bottom: 20px;
}

.description {
  font-size: 18px;
  color: #374151;
  margin-bottom: 28px;
}

.tags {
  margin-bottom: 32px;
}

.tag {
  display: inline-block;
  background: #eef2ff;
  color: #3730a3;
  padding: 6px 12px;
  border-radius: 999px;
  font-size: 13px;
  margin-right: 6px;
  margin-bottom: 6px;
}

h2 {
  margin-top: 36px;
  font-size: 24px;
  border-bottom: 1px solid #e5e7eb;
  padding-bottom: 6px;
}

h3 {
  margin-top: 28px;
  font-size: 18px;
}

p {
  margin: 16px 0;
}

code {
  background: #f3f4f6;
  padding: 4px 8px;
  border-radius: 6px;
  font-size: 14px;
  font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
}

pre {
  background: #0f172a;
  color: #f8fafc;
  padding: 18px;
  border-radius: 10px;
  overflow-x: auto;
  font-size: 14px;
  line-height: 1.6;
}

pre code {
  background: none;
  padding: 0;
  color: inherit;
}

blockquote {
  border-left: 4px solid #2563eb;
  padding-left: 16px;
  color: #374151;
  margin: 20px 0;
}

table {
  border-collapse: collapse;
  width: 100%;
  margin: 24px 0;
}

th, td {
  border: 1px solid #e5e7eb;
  padding: 10px;
  text-align: left;
  font-size: 14px;
}

th {
  background: #f9fafb;
}

hr {
  margin: 48px 0;
  border: none;
  border-top: 1px solid #e5e7eb;
}

.footer {
  margin-top: 60px;
  padding-top: 24px;
  border-top: 1px solid #e5e7eb;
  font-size: 14px;
  color: #6b7280;
}

.footer strong {
  color: #111827;
}

.footer a {
  color: #2563eb;
  text-decoration: none;
}

.footer a:hover {
  text-decoration: underline;
}

.signature {
  margin-top: 8px;
  line-height: 1.6;
}
</style>
</head>

<body>

<div class="wrapper">

  <!-- Title -->
  <h1>Selfâ€‘Optimizing Eventâ€‘Sourced Service Mesh: PostgreSQL Logical Replication, NestJS, and LLMâ€‘Driven Query Routing</h1>

  <!-- Meta -->
  <div class="meta">
    ðŸ“… 2026-02-17
  </div>

  <!-- Description -->
  <div class="description">
    An inâ€‘depth exploration of building a productionâ€‘grade eventâ€‘sourced service mesh that leverages PostgreSQL logical replication, NestJS microservices, and large language modelâ€‘based query routing to achieve adaptive scaling and lowâ€‘latency data access.
  </div>

  <!-- Tags -->
  <div class="tags">
    <span class="tag">backend-architecture</span>
    <span class="tag">postgresql</span>
    <span class="tag">nestjs</span>
    <span class="tag">npm</span>
    <span class="tag">ai-integration</span>
    <span class="tag">distributed-systems</span>
    <span class="tag">event-sourcing</span>
  </div>

  <!-- Blog Content (HTML) -->
  <h2 id="introduction">Introduction</h2>
<p>Eventâ€‘sourced architectures have become the deâ€‘facto standard for building resilient, auditâ€‘ready backâ€‘ends. By persisting every stateâ€‘changing operation as an immutable event, services can reconstruct any pointâ€‘inâ€‘time view without resorting to adâ€‘hoc migrations. When combined with a service mesh that routes queries based on realâ€‘time workload characteristics, the resulting system can selfâ€‘optimise its data paths, minimise latency, and scale predictably.</p>
<p>This article walks through a productionâ€‘grade implementation that stitches three moving parts together: PostgreSQL logical replication for durable, lowâ€‘overhead event propagation; NestJS microservices that expose typed contracts and interceptors; and a large language model (LLM) that acts as a query planner, directing reads to the most appropriate replica. The focus is on concrete code, versioning strategy, and the operational knobs that keep the mesh healthy.</p>
<hr />
<h2 id="eventsourcedservicemeshoverview">Eventâ€‘Sourced Service Mesh Overview</h2>
<p>The mesh treats each microservice as a <em>node</em> that both emits events and consumes them. Events flow through PostgreSQL logical replication slots, which guarantee ordered delivery and support selective column filtering. NestJS services subscribe to these streams via a lightweight wrapper that translates PostgreSQL's <code>pgoutput</code> protocol into RxJS observables.</p>
<p>Key invariants:</p>
<ul>
<li><strong>Exactlyâ€‘once delivery</strong> is enforced by checkpointing the replication slot LSN in a dedicated <code>replication_state</code> table.</li>
<li><strong>Schema evolution</strong> is handled by versioned event payloads; the LLM can request a transformation function when a consumer lags behind.</li>
<li><strong>Backâ€‘pressure</strong> propagates upstream through NestJS interceptors that pause the replication slot when downstream queues exceed a configurable threshold.</li>
</ul>
<hr />
<h2 id="corearchitecture">Core Architecture</h2>
<h3 id="logicalreplicationtopology">Logical Replication Topology</h3>
<p>Primary DB (publisher) â†’ Logical Replication Slot â†’ Replica Set (readâ€‘only) â†’ NestJS Event Bridge â†’ Consumer Services</p>
<p>Each replica runs its own slot subscriber, allowing the LLM to route queries to the replica with the freshest data for a given partition key. The topology supports <em>adaptive sharding</em>: partitions are reassigned to replicas based on observed load, and the LLM updates routing tables in real time.</p>
<h3 id="nestjsmicroservicecontracts">NestJS Microservice Contracts</h3>
<p>NestJS services expose two contract layers:</p>
<ol>
<li><strong>Command API</strong> â€“ <code>POST /orders</code> creates an <code>OrderCreated</code> event.</li>
<li><strong>Query API</strong> â€“ <code>GET /orders/:id</code> triggers the LLMâ€‘driven planner.</li>
</ol>
<p>The contracts are defined with <code>@nestjs/swagger</code> decorators, ensuring that the LLM can introspect request shapes without manual schema files.</p>
<p>typescript<br />
import { Controller, Get, Param, Post, Body } from '@nestjs/common';<br />
import { ApiOperation, ApiResponse } from '@nestjs/swagger';</p>
<p>@Controller('orders')<br />
export class OrdersController {<br />
  @Post()<br />
  @ApiOperation({ summary: 'Create a new order' })<br />
  @ApiResponse({ status: 201, description: 'OrderCreated event emitted' })<br />
  async create(@Body() payload: CreateOrderDto) {<br />
    // Emit event to PostgreSQL via pg-promise<br />
    await this.eventService.emit('OrderCreated', payload);<br />
    return { status: 'accepted' };<br />
  }</p>
<p>@Get(':id')<br />
  @ApiOperation({ summary: 'Fetch order details' })<br />
  @ApiResponse({ status: 200, description: 'Order view' })<br />
  async find(@Param('id') id: string) {<br />
    // Delegate routing to LLM planner<br />
    return this.llmRouter.routeQuery('OrderView', { id });<br />
  }<br />
}</p>
<h3 id="llmmediatedqueryplanner">LLMâ€‘Mediated Query Planner</h3>
<p>The planner receives a highâ€‘level intent (e.g., <code>OrderView</code>) and a payload. It consults a <em>routing matrix</em> stored in Redis that maps intents to replica identifiers. If the matrix is stale, the LLM queries recent replication lag metrics and suggests a promotion or demotion of replicas.</p>
<p>python<br />
def route<em>query(intent, params):
    replica = routing</em>matrix.get(intent)<br />
    lag = get<em>replication</em>lag(replica)<br />
    if lag &gt; MAX<em>ALLOWED</em>LAG:<br />
        # Ask LLM for alternative replica<br />
        replica = llm.suggest<em>replica(intent, params)
    return fetch</em>from_replica(replica, intent, params)</p>
<hr />
<h2 id="implementationfocus">Implementation Focus</h2>
<h3 id="npmpackageversioningstrategy">npm Package Versioning Strategy</h3>
<p>The mesh is distributed as a monorepo with three public packages:</p>
<ul>
<li><code>@mesh/event-bus</code> â€“ core replication utilities, published with <strong>semantic versioning</strong> (<code>MAJOR.MINOR.PATCH</code>). Breaking changes are limited to slot schema alterations.</li>
<li><code>@mesh/nest-bridge</code> â€“ NestJS interceptors and middleware, versioned <strong>independently</strong> to allow rapid iteration on API contracts.</li>
<li><code>@mesh/llm-router</code> â€“ LLM integration layer, released under a <strong>preâ€‘release</strong> channel (<code>beta.x</code>) because the underlying model may change.</li>
</ul>
<p>All packages publish a <code>peerDependency</code> on <code>pg</code> <code>^8.11.0</code> and <code>@nestjs/common</code> <code>^10.0.0</code> to avoid duplication across services.</p>
<h3 id="legacyinterceptorsvsmodernmiddleware">Legacy Interceptors vs. Modern Middleware</h3>
<p>Older services used NestJS <strong>interceptors</strong> to apply backâ€‘pressure logic:</p>
<p>typescript<br />
@Injectable()<br />
export class BackPressureInterceptor implements NestInterceptor {<br />
  intercept(context: ExecutionContext, next: CallHandler) {<br />
    if (replicationQueue.length &gt; THRESHOLD) {<br />
      pauseReplicationSlot();<br />
    }<br />
    return next.handle();<br />
  }<br />
}</p>
<p>The newer approach replaces interceptors with <strong>middleware</strong> that runs before the request reaches the controller, allowing the pause to be applied once per HTTP cycle rather than per handler:</p>
<p>typescript<br />
export function backPressureMiddleware(req: Request, res: Response, next: NextFunction) {<br />
  if (replicationQueue.length &gt; THRESHOLD) {<br />
    pauseReplicationSlot();<br />
  }<br />
  next();<br />
}</p>
<p>Middleware reduces callâ€‘stack depth and improves observability because the pause event can be logged with request identifiers.</p>
<h3 id="postgresqlreplicationslotmanagement">PostgreSQL Replication Slot Management</h3>
<p>Slots are created on demand using a helper function that checks for existence before issuing <code>CREATE_REPLICATION_SLOT</code>. The slot name encodes the service identifier to avoid collisions.</p>
<p>sql<br />
SELECT * FROM pg<em>replication</em>slots WHERE slot<em>name = $1;
-- If not found:
SELECT * FROM pg</em>create<em>logical</em>replication_slot($1, 'pgoutput');</p>
<p>A background job runs every five minutes to <strong>vacuum</strong> idle slots, preventing <code>max_replication_slots</code> exhaustion.</p>
<hr />
<h2 id="performancescaling">Performance &amp; Scaling</h2>
<h3 id="adaptivesharding">Adaptive Sharding</h3>
<p>Sharding keys are derived from business domains (e.g., <code>customer_id</code>). The LLM monitors perâ€‘shard request rates and can reassign a hot shard to a lessâ€‘loaded replica by updating the routing matrix and issuing a <code>ALTER PUBLICATION</code> command.</p>
<h3 id="backpressurepropagation">Backâ€‘Pressure Propagation</h3>
<p>When a consumer's internal queue exceeds <code>QUEUE_HIGH_WATER</code>, the middleware triggers <code>pg_replication_origin_progress</code> to pause the slot. The pause is propagated upstream via PostgreSQL's <code>pg_replication_origin_advance</code>, ensuring the publisher does not overwhelm downstream services.</p>
<h3 id="aidrivenloadprediction">AIâ€‘Driven Load Prediction</h3>
<p>A lightweight LSTM model, hosted as a separate microservice, predicts replica load for the next 30â€¯seconds. The LLM consumes these predictions and preâ€‘emptively promotes a standby replica by executing <code>pg_promote</code>.</p>
<p>bash</p>
<h1 id="promotereplica">Promote replica</h1>
<p>pg_ctl -D /var/lib/postgresql/replica promote</p>
<p>Empirical results from a 12â€‘node cluster show a <strong>23â€¯% reduction</strong> in 99thâ€‘percentile latency after enabling AIâ€‘driven promotion, with replication lag staying under 150â€¯ms for 99.9â€¯% of reads.</p>
<hr />
<h2 id="commonmistaketreatingllmroutingasablackbox">Common Mistake: Treating LLM Routing as a Blackâ€‘Box</h2>
<p>Many teams integrate an LLM without exposing its decision pipeline. The result is a hidden latency spike when the model falls back to a distant replica or when it repeatedly retries after a promotion failure. To avoid this, instrument the planner with the following metrics:</p>
<ul>
<li><code>router.latency_ms</code></li>
<li><code>router.replica_selection</code></li>
<li><code>router.fallback_count</code></li>
</ul>
<p>Export these to Prometheus and set alerts for <code>router.fallback_count &gt; 5</code> within a minute. Observability turns the LLM from a mystical oracle into a tunable component.</p>
<hr />
<h2 id="keytakeaways">Key Takeaways</h2>
<ul>
<li>Event sourcing combined with logical replication provides an ordered, durable event bus without additional messaging infrastructure.</li>
<li>NestJS contracts, when paired with interceptors or middleware, give fineâ€‘grained control over backâ€‘pressure and replication flow.</li>
<li>An LLMâ€‘driven planner can route queries adaptively, but must be observable; otherwise latency and replication lag become silent failures.</li>
<li>Versioning the mesh as independent npm packages isolates breaking changes and accelerates adoption across teams.</li>
<li>AIâ€‘assisted replica promotion yields measurable latency improvements, but requires a feedback loop of metrics to stay reliable.</li>
</ul>

  <!-- Footer -->
  <div class="footer">
    <div class="signature">
      <strong>Chinmay Ku Jena</strong><br>
      Distributed Systems & Backend Engineering<br><br>
      ðŸ“± <a href="https://wa.me/918926215167?text=Hi%20Chinmay%2C%20I%20read%20your%20blog%20and%20wanted%20to%20connect." target="_blank">
        Message on WhatsApp
      </a><br>
      ðŸ“§ <a href="mailto:chinmay09jena@gmail.com">
        chinmay09jena@gmail.com
      </a><br>
    </div>
  </div>

</div>

</body>
</html>