<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
body {
  margin: 0;
  padding: 0;
  background-color: #f6f8fa;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
}

.wrapper {
  max-width: 760px;
  margin: 40px auto;
  background: #ffffff;
  padding: 48px;
  border-radius: 12px;
  box-shadow: 0 8px 24px rgba(0,0,0,0.06);
  line-height: 1.7;
  color: #111827;
}

h1 {
  font-size: 34px;
  margin-bottom: 12px;
  line-height: 1.3;
}

.meta {
  font-size: 14px;
  color: #6b7280;
  margin-bottom: 20px;
}

.description {
  font-size: 18px;
  color: #374151;
  margin-bottom: 28px;
}

.tags {
  margin-bottom: 32px;
}

.tag {
  display: inline-block;
  background: #eef2ff;
  color: #3730a3;
  padding: 6px 12px;
  border-radius: 999px;
  font-size: 13px;
  margin-right: 6px;
  margin-bottom: 6px;
}

h2 {
  margin-top: 36px;
  font-size: 24px;
  border-bottom: 1px solid #e5e7eb;
  padding-bottom: 6px;
}

h3 {
  margin-top: 28px;
  font-size: 18px;
}

p {
  margin: 16px 0;
}

code {
  background: #f3f4f6;
  padding: 4px 8px;
  border-radius: 6px;
  font-size: 14px;
  font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
}

pre {
  background: #0f172a;
  color: #f8fafc;
  padding: 18px;
  border-radius: 10px;
  overflow-x: auto;
  font-size: 14px;
  line-height: 1.6;
}

pre code {
  background: none;
  padding: 0;
  color: inherit;
}

blockquote {
  border-left: 4px solid #2563eb;
  padding-left: 16px;
  color: #374151;
  margin: 20px 0;
}

table {
  border-collapse: collapse;
  width: 100%;
  margin: 24px 0;
}

th, td {
  border: 1px solid #e5e7eb;
  padding: 10px;
  text-align: left;
  font-size: 14px;
}

th {
  background: #f9fafb;
}

hr {
  margin: 48px 0;
  border: none;
  border-top: 1px solid #e5e7eb;
}

.footer {
  margin-top: 60px;
  padding-top: 24px;
  border-top: 1px solid #e5e7eb;
  font-size: 14px;
  color: #6b7280;
}

.footer strong {
  color: #111827;
}

.footer a {
  color: #2563eb;
  text-decoration: none;
}

.footer a:hover {
  text-decoration: underline;
}

.signature {
  margin-top: 8px;
  line-height: 1.6;
}
</style>
</head>

<body>

<div class="wrapper">

  <!-- Title -->
  <h1>Event-Driven Real-Time Recommendation Engine: NestJS, PostgreSQL Logical Replication, and LLM-Based Ranking</h1>

  <!-- Meta -->
  <div class="meta">
    üìÖ 2026-02-25
  </div>

  <!-- Description -->
  <div class="description">
    An in-depth guide to building a low-latency recommendation service using event sourcing, PostgreSQL logical replication, NestJS microservices, and large language model inference for dynamic ranking, covering architecture, data modeling, CI/CD, and production trade‚Äëoffs.
  </div>

  <!-- Tags -->
  <div class="tags">
    <span class="tag">backend-architecture</span>
    <span class="tag">postgresql</span>
    <span class="tag">nestjs</span>
    <span class="tag">event-driven</span>
    <span class="tag">llm-integration</span>
    <span class="tag">distributed-systems</span>
    <span class="tag">performance-optimization</span>
  </div>

  <!-- Blog Content (HTML) -->
  <p>Technical introduction</p>
<p>Real‚Äëtime recommendation systems must reconcile two competing demands: sub‚Äëmillisecond latency for the end user and high‚Äëthroughput processing of noisy interaction streams. A na√Øve monolith that reads directly from a relational store cannot satisfy both, because write amplification and lock contention quickly dominate. By decoupling ingestion, persistence, and ranking into separate services, we can apply specialized optimizations‚ÄîKafka for durable streaming, PostgreSQL logical replication for source‚Äëof‚Äëtruth consistency, and a GPU‚Äëbacked LLM for contextual ranking.</p>
<p>The pattern presented here treats user actions (click, view, purchase) as immutable events stored in a PostgreSQL table. Logical replication streams row‚Äëlevel changes to a NestJS microservice mesh, which materializes lightweight read models and forwards enriched payloads to an LLM inference service. The result is a recommendation API that delivers personalized results within 30‚ÄØms while preserving strong consistency guarantees for downstream analytics.</p>
<h2 id="corearchitecture">Core Architecture</h2>
<ul>
<li><strong>Ingress</strong>: Kafka topics receive JSON‚Äëencoded interaction events from front‚Äëend SDKs.</li>
<li><strong>Persistence</strong>: A primary PostgreSQL instance hosts the canonical <code>user_events</code> table. Logical replication publishes <code>INSERT</code>/<code>UPDATE</code> changes to a replica slot.</li>
<li><strong>Microservice Mesh</strong>: NestJS services subscribe to the replication stream via the <code>pg-logical-replication</code> library, transform rows into domain events, and publish them to internal NATS subjects.</li>
<li><strong>Read Models</strong>: Materialized views and sharded tables provide low‚Äëlatency look‚Äëups for user‚Äëprofile and item‚Äëpopularity data.</li>
<li><strong>Ranking Service</strong>: A separate container runs a quantized LLM (e.g., Llama‚Äë2‚Äë7B‚ÄëChat) behind a FastAPI wrapper. NestJS calls it via gRPC, passing a context vector built from the read model.</li>
<li><strong>API Gateway</strong>: NestJS <code>@Controller</code> endpoints expose <code>/recommendations/:userId</code> with response times measured in tens of milliseconds.</li>
</ul>
<h2 id="schemafirstdatamodelingcdc">Schema‚ÄëFirst Data Modeling &amp; CDC</h2>
<p>typescript<br />
// src/entities/user-event.entity.ts<br />
import { Entity, PrimaryGeneratedColumn, Column, CreateDateColumn } from 'typeorm';</p>
<p>@Entity('user_events')<br />
export class UserEvent {<br />
  @PrimaryGeneratedColumn()<br />
  id: number;</p>
<p>@Column({ type: 'uuid' })<br />
  user_id: string;</p>
<p>@Column({ type: 'varchar' })<br />
  event_type: string; // click, view, purchase</p>
<p>@Column({ type: 'jsonb' })<br />
  payload: Record<string, any>;</p>
<p>@CreateDateColumn({ type: 'timestamptz' })<br />
  created_at: Date;<br />
}</p>
<p>The table is defined with <code>REPLICA IDENTITY FULL</code> to ensure that <code>UPDATE</code> and <code>DELETE</code> operations emit complete row images. A replication slot is created once during deployment:</p>
<pre><code>SELECT * FROM pg_create_logical_replication_slot('event_slot', 'pgoutput');
</code></pre>
<p>NestJS subscribes using a streaming cursor:</p>
<pre><code>const client = new PgLogicalReplication({ connectionString: process.env.DATABASE_URL });
const stream = client.subscribe('event_slot');
stream.on('data', async (msg) =&gt; {
  const event = JSON.parse(msg.payload);
  await this.eventBus.publish(new UserInteractionEvent(event));
});
</code></pre>
<h2 id="llminferenceserviceintegration">LLM Inference Service Integration</h2>
<p>The ranking service expects a JSON payload containing a user embedding, candidate item IDs, and recent context events. A minimal FastAPI wrapper looks like:</p>
<pre><code>from fastapi import FastAPI, Body
from pydantic import BaseModel
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

app = FastAPI()
model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-2-7b-chat-hf', torch_dtype=torch.float16).to('cuda')
tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-chat-hf')

class RankRequest(BaseModel):
    user_id: str
    candidates: list[int]
    context: list[dict]

@app.post('/rank')
async def rank(req: RankRequest = Body(...)):
    prompt = build_prompt(req.user_id, req.candidates, req.context)
    inputs = tokenizer(prompt, return_tensors='pt').to('cuda')
    output = model.generate(**inputs, max_new_tokens=5)
    scores = parse_scores(output)
    return {'ranking': scores}
</code></pre>
<p>NestJS calls the service via gRPC (or HTTP) and caches the embedding for 5‚ÄØminutes using <code>@Cacheable</code>.</p>
<h2 id="versioningpackagemanagement">Versioning &amp; Package Management</h2>
<p>All shared DTOs live in an internal npm package <code>@company/recommendation-proto</code>. Semantic versioning is enforced with <code>npm version patch</code> in CI pipelines. The CI workflow publishes the package to a private registry only after integration tests pass against a spin‚Äëup PostgreSQL replica and a mock LLM endpoint.</p>
<p>yaml</p>
<h1 id="githubworkflowsciyml">.github/workflows/ci.yml</h1>
<p>name: CI<br />
on: [push, pull_request]<br />
jobs:<br />
  build:<br />
    runs-on: ubuntu-latest<br />
    steps:<br />
      - uses: actions/checkout@v3<br />
      - name: Set up Node<br />
        uses: actions/setup-node@v3<br />
        with:<br />
          node-version: '20'<br />
          registry-url: 'https://npm.pkg.github.com'<br />
      - run: npm ci<br />
      - run: npm run test:integration<br />
      - if: success()<br />
        run: npm version patch &amp;&amp; npm publish</p>
<h2 id="performancescaling">Performance &amp; Scaling</h2>
<h3 id="latencybudgeting">Latency budgeting</h3>
<ul>
<li><strong>Ingestion ‚Üí Kafka</strong>: &lt;‚ÄØ5‚ÄØms (batch size 1, compression lz4)</li>
<li><strong>PostgreSQL ‚Üí Replication</strong>: 10‚Äë15‚ÄØms average lag under 10‚ÄØk RPS</li>
<li><strong>NestJS transformation</strong>: 2‚Äë3‚ÄØms per event</li>
<li><strong>LLM inference</strong>: 12‚Äë18‚ÄØms per request on a single A100 GPU (quantized model)</li>
<li><strong>API response</strong>: &lt;‚ÄØ30‚ÄØms 99th percentile</li>
</ul>
<h3 id="backpressurehandling">Back‚Äëpressure handling</h3>
<p>NestJS leverages RxJS <code>bufferTime</code> to accumulate events when the LLM queue exceeds a configurable threshold. Excess events are persisted to a secondary ‚Äúslow‚Äëlane‚Äù table and re‚Äëprocessed during off‚Äëpeak windows.</p>
<h3 id="readscale">Read‚Äëscale</h3>
<p>Materialized views <code>user_profile_mv</code> and <code>item_popularity_mv</code> are refreshed every 30‚ÄØseconds using <code>REFRESH MATERIALIZED VIEW CONCURRENTLY</code>. Sharding is achieved with PostgreSQL table partitioning on <code>user_id</code> hash, allowing horizontal scaling across three read replicas.</p>
<h3 id="gpuacceleratedserving">GPU‚Äëaccelerated serving</h3>
<p>Container orchestration (Kubernetes) runs the LLM service with <code>nvidia.com/gpu: 1</code>. Autoscaling policies trigger additional pods when the average GPU utilization exceeds 70‚ÄØ%.</p>
<h2 id="commonpitfalls">Common Pitfalls</h2>
<ol>
<li><strong>Equating eventual consistency with stale recommendations</strong> ‚Äì If the replication slot falls behind, the ranking service may use outdated popularity scores. Mitigate by monitoring <code>pg_replication_slots</code> lag and implementing a fallback to the last‚Äëknown‚Äëgood snapshot.</li>
<li><strong>Neglecting schema evolution hygiene</strong> ‚Äì Adding a column to <code>user_events</code> without updating the replication slot‚Äôs <code>REPLICA IDENTITY</code> can cause missing fields in downstream consumers. Adopt a migration checklist that includes replication slot recreation and versioned DTO updates.</li>
<li><strong>Polyglot persistence friction</strong> ‚Äì Storing the same entity in both PostgreSQL and a Redis cache without a clear ownership model leads to race conditions. Define the database as the source of truth; caches must be invalidated via event listeners.</li>
</ol>
<h2 id="keytakeaways">Key Takeaways</h2>
<ul>
<li>Event sourcing with PostgreSQL logical replication provides strong consistency while keeping the write path simple.</li>
<li>NestJS microservices act as a thin transformation layer, enabling language‚Äëagnostic downstream services such as GPU‚Äëbacked LLM rankers.</li>
<li>Materialized views and hash partitioning deliver sub‚Äë30‚ÄØms read latency at scale.</li>
<li>Rigorous schema‚Äëfirst modeling and versioned npm packages prevent drift between producers and consumers.</li>
<li>Monitoring replication lag and back‚Äëpressure thresholds is essential to avoid stale recommendations.</li>
</ul>

  <!-- Footer -->
  <div class="footer">
    <div class="signature">
      <strong>Chinmay Ku Jena</strong><br>
      Distributed Systems & Backend Engineering<br><br>
      üì± <a href="https://wa.me/918926215167?text=Hi%20Chinmay%2C%20I%20read%20your%20blog%20and%20wanted%20to%20connect." target="_blank">
        Message on WhatsApp
      </a><br>
      üìß <a href="mailto:chinmay09jena@gmail.com">
        chinmay09jena@gmail.com
      </a><br>
    </div>
  </div>

</div>

</body>
</html>